{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":90279,"databundleVersionId":10477255,"sourceType":"competition"}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import necessary libraries\nimport tensorflow as tf  # TensorFlow for deep learning\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator  # Image preprocessing and augmentation\nfrom tensorflow.keras.applications import InceptionV3  # Pre-trained InceptionV3 model\nfrom tensorflow.keras.models import Model  # Model creation\nfrom tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D  # Layers for custom model\nfrom tensorflow.keras.optimizers import Adam  # Optimizer\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping  # Callbacks for training\nfrom sklearn.metrics import f1_score, confusion_matrix, ConfusionMatrixDisplay  # Evaluation metrics\nimport matplotlib.pyplot as plt  # Visualization\nimport pandas as pd  # For loading and processing CSV data\nfrom tensorflow.keras.layers import BatchNormalization, LeakyReLU  # Additional layers\n\n# Paths to the datasets\ntrain_dir = '/kaggle/input/datathon-ai-qualification-round/train/train'\ntest_dir = '/kaggle/input/datathon-ai-qualification-round/test/test'\ntrain_csv = '/kaggle/input/datathon-ai-qualification-round/train_data.csv'\ntest_csv = '/kaggle/input/datathon-ai-qualification-round/test.csv'\n\n# Load train and test datasets from CSV files\ntrain_df = pd.read_csv(train_csv)\ntest_df = pd.read_csv(test_csv)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T06:46:20.396790Z","iopub.execute_input":"2024-12-16T06:46:20.397116Z","iopub.status.idle":"2024-12-16T06:48:30.061821Z","shell.execute_reply.started":"2024-12-16T06:46:20.397089Z","shell.execute_reply":"2024-12-16T06:48:30.060468Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Data augmentation with ImageDataGenerator\ntrain_datagen = ImageDataGenerator(\n    rescale=1.0/255,  # Normalize pixel values to range [0, 1]\n    rotation_range=35,  # Random rotation by up to 35 degrees\n    width_shift_range=0.3,  # Random horizontal shift\n    height_shift_range=0.3,  # Random vertical shift\n    shear_range=0.3,  # Shear transformation\n    zoom_range=0.3,  # Random zoom\n    horizontal_flip=True,  # Random horizontal flipping\n    fill_mode='nearest',  # Fill mode for transformed pixels\n    validation_split=0.2  # Split data into 80% training and 20% validation\n)\n\n# Train generator: Generates augmented images for training\ntrain_generator = train_datagen.flow_from_dataframe(\n    dataframe=train_df,  # Input DataFrame\n    directory=train_dir,  # Directory containing training images\n    x_col='filename',  # Column containing image filenames\n    y_col='city',  # Column containing target labels\n    target_size=(640, 640),  # Resize images to 640x640\n    batch_size=32,  # Number of images per batch\n    class_mode='categorical',  # Output labels are categorical\n    subset='training'  # Use training subset\n)\n\n# Validation generator: Generates augmented images for validation\nvalidation_generator = train_datagen.flow_from_dataframe(\n    dataframe=train_df,\n    directory=train_dir,\n    x_col='filename',\n    y_col='city',\n    target_size=(640, 640),\n    batch_size=32,\n    class_mode='categorical',\n    subset='validation'  # Use validation subset\n)\n\n# Test generator: Generates images for testing without labels\ntest_datagen = ImageDataGenerator(rescale=1.0/255)  # Normalize pixel values\ntest_generator = test_datagen.flow_from_dataframe(\n    dataframe=test_df,\n    directory=test_dir,\n    x_col='filename',\n    y_col=None,  # No labels in test data\n    target_size=(640, 640),\n    batch_size=32,\n    class_mode=None,\n    shuffle=False  # Do not shuffle test data\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T06:46:20.396790Z","iopub.execute_input":"2024-12-16T06:46:20.397116Z","iopub.status.idle":"2024-12-16T06:48:30.061821Z","shell.execute_reply.started":"2024-12-16T06:46:20.397089Z","shell.execute_reply":"2024-12-16T06:48:30.060468Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load InceptionV3 pre-trained model without the top layer\nbase_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(640, 640, 3))\n\n# Add custom layers on top of the base model\nx = base_model.output\nx = GlobalAveragePooling2D()(x)  # Reduce feature maps to a single vector\nx = Dense(108, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0005))(x)  # Fully connected layer with L2 regularization\nx = BatchNormalization()(x)  # Normalize activations\nx = Dropout(0.5)(x)  # Dropout for reducing overfitting\noutput = Dense(3, activation='softmax')(x)  # Output layer with 3 classes (softmax activation)\n\n# Create the final model\nmodel = Model(inputs=base_model.input, outputs=output)\n\n# Freeze the base model layers to preserve pre-trained weights\nfor layer in base_model.layers:\n    layer.trainable = False\n\n# Unfreeze the last 130 layers for fine-tuning\nfor layer in base_model.layers[-130:]:\n    layer.trainable = True\n\n# Compile the model with optimizer, loss, and metrics\nmodel.compile(\n    optimizer=Adam(learning_rate=0.0001),  # Adam optimizer with a small learning rate\n    loss='categorical_crossentropy',  # Loss function for multi-class classification\n    metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), tf.keras.metrics.AUC()]  # Evaluation metrics\n)\n\n# Define callbacks\nlr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1)  # Reduce learning rate if no improvement\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)  # Stop training if no improvement\n\n# Train the model\nhistory = model.fit(\n    train_generator,\n    validation_data=validation_generator,\n    epochs=30,  # Train for 30 epochs\n    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n    validation_steps=validation_generator.samples // validation_generator.batch_size,\n    callbacks=[lr_scheduler, early_stopping],\n    verbose=1\n)\n\n# Fine-tuning: Train the model further with a reduced learning rate\nhistory_finetune = model.fit(\n    train_generator,\n    validation_data=validation_generator,\n    epochs=20,\n    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n    validation_steps=validation_generator.samples // validation_generator.batch_size,\n    callbacks=[lr_scheduler, early_stopping],\n    verbose=1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T06:46:20.396790Z","iopub.execute_input":"2024-12-16T06:46:20.397116Z","iopub.status.idle":"2024-12-16T06:48:30.061821Z","shell.execute_reply.started":"2024-12-16T06:46:20.397089Z","shell.execute_reply":"2024-12-16T06:48:30.060468Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save the trained model\nmodel.save(\"inceptionv3_optimized_model.h5\")\nprint(\"Model kaydedildi: inceptionv3_optimized_model.h5\")\n\n# Plot training and validation loss\nplt.figure(figsize=(14, 6))\nplt.subplot(1, 2, 1)\nplt.plot(history.history['loss'] + history_finetune.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'] + history_finetune.history['val_loss'], label='Validation Loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\n# Plot training and validation accuracy\nplt.subplot(1, 2, 2)\nplt.plot(history.history['accuracy'] + history_finetune.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'] + history_finetune.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()\n\n# Predict on the validation set\nval_predictions = model.predict(validation_generator)\ny_true = validation_generator.classes\ny_pred = val_predictions.argmax(axis=1)\n\n# Calculate the Macro F1 score\nf1_macro = f1_score(y_true, y_pred, average='macro')\nprint(f\"InceptionV3 Fine-Tuned Macro F1 Score: {f1_macro}\")\n\n# Predict on the test set\npredictions = model.predict(test_generator)\npredicted_classes = predictions.argmax(axis=1)\n\n# Map predicted class indices to class names\nlabel_map = {v: k for k, v in train_generator.class_indices.items()}\ntest_df['city'] = [label_map[class_idx] for class_idx in predicted_classes]\n\n# Save predictions to a submission file\nsubmission_path = '/kaggle/working/submission.csv'\ntest_df[['filename', 'city']].to_csv(submission_path, index=False)\nprint(f\"Submission dosyasÄ± kaydedildi: {submission_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T06:46:20.396790Z","iopub.execute_input":"2024-12-16T06:46:20.397116Z","iopub.status.idle":"2024-12-16T06:48:30.061821Z","shell.execute_reply.started":"2024-12-16T06:46:20.397089Z","shell.execute_reply":"2024-12-16T06:48:30.060468Z"}},"outputs":[],"execution_count":null}]}